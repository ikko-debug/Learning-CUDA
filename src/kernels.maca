#include <algorithm>
#include <cmath>
#include <vector>
#include <common/maca_fp16.h>

#include "../tester/utils.h"

#define BLOCK_SIZE 256




template <typename T>
__device__ __forceinline__ T warpReduceSum(T val) {
    for (int offset = 32 / 2; offset > 0; offset >>= 1) {
        val += __shfl_down_sync(0xffffffff, val, offset);
    }
    return val;
}

template <typename T>
__device__ __forceinline__ T blockReduceSum(T val) {
    static __shared__ T shared[32]; 
    int lane = threadIdx.x % 32; 
    int wid  = threadIdx.x / 32; 

    val = warpReduceSum(val);
    if (lane == 0) shared[wid] = val;
    __syncthreads();

    val = (threadIdx.x < blockDim.x / 32) ? shared[lane] : (T)0;
    if (wid == 0) val = warpReduceSum(val);

    return val;
}

template <typename T>
__device__ __forceinline__ float to_float(T v);

template <>
__device__ __forceinline__ float to_float<float>(float v) { return v; }

template <>
__device__ __forceinline__ float to_float<int>(int v) { return (float)v; }

template <>
__device__ __forceinline__ float to_float<half>(half v) {
    return __half2float(v);
}

template <typename T>
__device__ __forceinline__ T from_float(float v);

template <>
__device__ __forceinline__ float from_float<float>(float v) { return v; }

template <>
__device__ __forceinline__ int from_float<int>(float v) { return (int)v; }

template <>
__device__ __forceinline__ half from_float<half>(float v) {
    return __float2half(v);
}


template <typename T>
__global__ void traceKernel(const T* __restrict__ input, size_t rows, size_t cols, size_t n, T* out) {
    size_t idx = blockIdx.x * blockDim.x + threadIdx.x;
    size_t stride = blockDim.x * gridDim.x;
    T local_sum = 0;

    for (size_t i = idx; i < n; i += stride) {
        local_sum += input[i * cols + i];
    }

    local_sum = blockReduceSum(local_sum);

    if (threadIdx.x == 0) {
        atomicAdd(out, local_sum);
    }
}

template <typename T>
__global__ void flash_attention_v1_kernel(
    const T* Q, const T* K, const T* V, T* O,
    int batch_size, int target_seq_len, int src_seq_len,
    int query_heads, int kv_heads, int head_dim, bool is_causal, float scale) {
    
    const int q_idx = blockIdx.x;
    const int tid = threadIdx.x;

    if (q_idx >= batch_size * target_seq_len * query_heads || tid >= head_dim) return;

    int tmp = q_idx;
    int qh = tmp % query_heads;
    tmp /= query_heads;
    int t = tmp % target_seq_len;
    int b = tmp / target_seq_len;
    int kv_h = (qh * kv_heads) / query_heads;

    float q_val = to_float(Q[q_idx * head_dim + tid]);
    float m_i = -INFINITY;
    float l_i = 0.0f;
    float o_i = 0.0f;

    extern __shared__ float s_mem[];
    float* s_k = s_mem; 
    float* s_v = s_mem + head_dim; 
    float* s_dot = s_mem + 2 * head_dim; 
    float* s_red = s_mem + 2 * head_dim + 1; 

    for (int j = 0; j < src_seq_len; ++j) {
        if (is_causal && j > t) continue;

        const T* k_ptr = K + (((b * src_seq_len + j) * kv_heads + kv_h) * head_dim);
        const T* v_ptr = V + (((b * src_seq_len + j) * kv_heads + kv_h) * head_dim);

        s_k[tid] = to_float(k_ptr[tid]);
        s_v[tid] = to_float(v_ptr[tid]);
        __syncthreads();

        float score = q_val * s_k[tid];
        s_red[tid] = score;
        __syncthreads();
        for (int stride = (head_dim + 1) / 2; stride > 0; stride = (stride == 1) ? 0 : (stride + 1) / 2) {
            if (tid < stride && (tid + stride) < head_dim) {
                s_red[tid] += s_red[tid + stride];
            }
            __syncthreads();
        }

        if (tid == 0) s_dot[0] = s_red[0] * scale;
        __syncthreads();

        float dot = s_dot[0];
        float m_prev = m_i;
        m_i = fmaxf(m_prev, dot);
        float p_prev = expf(m_prev - m_i);
        float p_curr = expf(dot - m_i);
        
        float l_prev = l_i;
        l_i = l_prev * p_prev + p_curr;
        o_i = (o_i * l_prev * p_prev + p_curr * s_v[tid]) / l_i;
        __syncthreads();
    }

    O[q_idx * head_dim + tid] = from_float<T>(o_i);
}



template <typename T>
T trace(const std::vector<T>& h_input, size_t rows, size_t cols) {
    if (rows == 0 || cols == 0) return T(0);
    size_t n = std::min(rows, cols);
    size_t total_elems = rows * cols;

    T *d_input, *d_out;
    // 使用 macaMalloc 代替 cudaMalloc
    RUNTIME_CHECK(macaMalloc(&d_input, total_elems * sizeof(T)));
    RUNTIME_CHECK(macaMalloc(&d_out, sizeof(T)));
    RUNTIME_CHECK(macaMemcpy(d_input, h_input.data(), total_elems * sizeof(T), macaMemcpyHostToDevice));
    RUNTIME_CHECK(macaMemset(d_out, 0, sizeof(T)));

    traceKernel<T><<< (n + BLOCK_SIZE - 1) / BLOCK_SIZE, BLOCK_SIZE >>>(d_input, rows, cols, n, d_out);
    RUNTIME_CHECK(macaGetLastError());
    RUNTIME_CHECK(macaDeviceSynchronize());

    T h_out;
    RUNTIME_CHECK(macaMemcpy(&h_out, d_out, sizeof(T), macaMemcpyDeviceToHost));
    RUNTIME_CHECK(macaFree(d_input));
    RUNTIME_CHECK(macaFree(d_out));
    return h_out;
}

template <typename T>
void flashAttention(const std::vector<T>& h_q, const std::vector<T>& h_k,
                    const std::vector<T>& h_v, std::vector<T>& h_o,
                    int batch_size, int target_seq_len, int src_seq_len, 
                    int query_heads, int kv_heads, int head_dim, bool is_causal) {
    
    size_t q_elems = batch_size * target_seq_len * query_heads * head_dim;
    size_t k_elems = batch_size * src_seq_len * kv_heads * head_dim;
    h_o.resize(q_elems);

    T *d_q, *d_k, *d_v, *d_o;
    RUNTIME_CHECK(macaMalloc(&d_q, q_elems * sizeof(T)));
    RUNTIME_CHECK(macaMalloc(&d_k, k_elems * sizeof(T)));
    RUNTIME_CHECK(macaMalloc(&d_v, k_elems * sizeof(T)));
    RUNTIME_CHECK(macaMalloc(&d_o, q_elems * sizeof(T)));

    RUNTIME_CHECK(macaMemcpy(d_q, h_q.data(), q_elems * sizeof(T), macaMemcpyHostToDevice));
    RUNTIME_CHECK(macaMemcpy(d_k, h_k.data(), k_elems * sizeof(T), macaMemcpyHostToDevice));
    RUNTIME_CHECK(macaMemcpy(d_v, h_v.data(), k_elems * sizeof(T), macaMemcpyHostToDevice));
    RUNTIME_CHECK(macaMemset(d_o, 0, q_elems * sizeof(T)));

    dim3 grid(batch_size * target_seq_len * query_heads);
    dim3 block(head_dim);
    size_t shared_bytes = (3 * head_dim + 1) * sizeof(float);
    float scale = 1.0f / sqrtf((float)head_dim);

    flash_attention_v1_kernel<T><<<grid, block, shared_bytes>>>(
        d_q, d_k, d_v, d_o, batch_size, target_seq_len, src_seq_len, 
        query_heads, kv_heads, head_dim, is_causal, scale);
    RUNTIME_CHECK(macaGetLastError());
    RUNTIME_CHECK(macaDeviceSynchronize());

    RUNTIME_CHECK(macaMemcpy(h_o.data(), d_o, q_elems * sizeof(T), macaMemcpyDeviceToHost));

    RUNTIME_CHECK(macaFree(d_q));
    RUNTIME_CHECK(macaFree(d_k));
    RUNTIME_CHECK(macaFree(d_v));
    RUNTIME_CHECK(macaFree(d_o));
}


template int trace<int>(const std::vector<int>&, size_t, size_t);
template float trace<float>(const std::vector<float>&, size_t, size_t);
template void flashAttention<float>(const std::vector<float>&, const std::vector<float>&, const std::vector<float>&, std::vector<float>&, int, int, int, int, int, int, bool);
template void flashAttention<half>(const std::vector<half>&, const std::vector<half>&, const std::vector<half>&, std::vector<half>&, int, int, int, int, int, int, bool);